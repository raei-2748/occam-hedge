\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage[round,authoryear]{natbib}
\usepackage{authblk}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{fancyhdr}
\usepackage{hyperref}
\usepackage{amsthm}
\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\usepackage[T1]{fontenc}
\usepackage{textcomp}

\newtheoremstyle{uprightprop} % name
  {6pt}{6pt}                  % space above/below
  {\normalfont}               % body font (upright, not italic)
  {}                          % indent
  {\bfseries}                 % head font
  {.}                         % punctuation after head
  {0.5em}                     % space after head
  {}                          % head spec

\theoremstyle{uprightprop}
\newtheorem{proposition}{Proposition}[section]

\title{Occam’s Hedge under Relative Entropy Uncertainty}
\author{Ray Wang}
\affil{Knox Grammar School}
\affil{\texttt{raywang886@gmail.com}}
\date{}

\begin{document}
\maketitle

\begin{abstract}
We study robustness of deep hedging policies with execution costs under regime shifts in which microstructure proxies can invert economic meaning. We formalize this failure mode as \emph{semantic inversion}: a feature whose effect on marginal execution costs changes sign across regimes. Robustness is evaluated via worst-case tail risk over Kullback--Leibler bounded neighborhoods of the training path measure, yielding stress-severity indexed robustness curves. 

We propose \emph{Occam’s Hedge}, which constrains representation bandwidth using a variational KL-to-prior penalty, limiting reliance on regime-contingent microstructure detail. In a controlled regime-switching simulator engineered to induce inversion in the activity--impact channel, microstructure-heavy policies exhibit substantially larger stress degradation than payoff-anchored (Greek-based) policies. Tightening the information budget reduces turnover, mitigates degradation, and flattens robustness curves, producing an explicit robustness--information frontier.
\end{abstract}

\noindent\textbf{Keywords:} deep hedging; execution costs; model risk; distributional robustness; information bottleneck; market microstructure.\\
\textbf{JEL Codes:} G13; C61; G11.

\section{Introduction}
Deep hedging's flexibility to condition on rich information sets creates a Lucas Critique vulnerability: microstructure signals that improve in-sample hedging performance can exhibit regime-dependent meaning that inverts under stress \citep{buehler2019deep, Lucas1976}. When a policy learns that high trading volume predicts low execution costs (a correlation that holds in liquid markets), it concentrates activity in precisely those states where funding constraints transform volume from a proxy for depth into a marker of distressed liquidation \citep{easley2012vpin,brunnermeier2009liquidity,duffie2020intermediation}. This is more than classical statistical overfitting. It reflects a structural incentive of empirical risk minimization: any correlation that reduces training loss is rewarded, even if that correlation is an equilibrium outcome tied to a particular liquidity regime. When intermediation constraints bind, microstructure-heavy hedges can concentrate trading in states where marginal execution costs are highest.

Standard scenario stress tests do not quantify this vulnerability. A handful of historical crises may reveal isolated breakdowns, but they provide neither a comparable notion of robustness across policies nor an indication of how far the market can drift before performance degrades. We therefore treat stress as a controlled perturbation of the training environment: let $P_0$ denote the baseline path distribution; we evaluate robustness as worst-case hedging loss over alternative distributions in a relative-entropy neighborhood of $P_0$, indexed by a KL stress budget.

Within this framework, we introduce \emph{Occam's Hedge}: an information-budgeted deep hedging policy that limits reliance on regime-contingent microstructure detail by constraining the controller's representation bandwidth. Drawing on rational inattention and variational information bottleneck ideas \citep{sims2003rational,tishby2000information,alemi2017deep}, the policy acts on a stochastic representation and pays an inner KL-to-prior cost for extracting distribution-specific detail. The outer KL defines the adversarial neighborhood for stress evaluation; the inner KL prices representation complexity. We hypothesize that robust risk grows faster with stress severity for microstructure-heavy policies than for payoff-anchored (Greek-based) policies, and that tightening the information budget flattens this robust-risk curve, yielding an explicit robustness-information frontier.

\subsection*{Contributions}
(i) We formalize a representation-level failure mode in deep hedging with execution costs: policies trained by empirical risk minimization can exploit microstructure proxies whose marginal effect on execution costs is regime-dependent and can invert, leading to concentrated trading in high-cost states under stress. 
(ii) We introduce a dual-KL evaluation-and-design framework: an \emph{outer} KL neighborhood over path measures produces a stress-severity indexed robustness curve for any learned policy, while an \emph{inner} KL-to-prior penalty constrains representation information and yields an explicit robustness--information tradeoff.
(iii) In a controlled simulator with an engineered inversion in the activity--impact channel, we provide mechanism diagnostics (sign-flips in marginal cost sensitivity and changes in policy trading patterns) and compare Occam regularization against parameter regularization and input-noise baselines, reporting robustness curves with uncertainty across seeds.


\section{Literature Review}

Related work spans (i) learning-based hedging under frictions, (ii) market microstructure and regime-dependent execution costs, (iii) robust control and model risk under relative-entropy uncertainty, and (iv) information-regularized decision rules. Our contribution sits at their intersection, but with a sharper focus: we quantify hedging-policy fragility under regime shifts driven by \emph{semantic instability} of microstructure proxies, and we test whether limiting representation information mitigates this fragility. 
Most existing deep-hedging studies evaluate out-of-sample performance under the same data-generating regime or under a small set of hand-designed stress scenarios, which makes robustness hard to compare across policies and stress intensities. Meanwhile, the relative-entropy model-risk literature provides a computable worst-case reweighting operator, but it has rarely been used to produce robustness curves for learned hedging policies or to study how representation choice interacts with stress. To our knowledge, no prior work jointly (a) evaluates deep hedges under a KL-bounded \emph{path-measure} stress operator around the training distribution and (b) links robustness to an explicit \emph{representation information cost}.

\subsection{Learning-Based Hedging under Frictions}

Deep hedging formulates dynamic hedging with transaction costs and impact as a stochastic control problem solved with flexible function approximators \citep{buehler2019deep}. Subsequent work extends the framework to richer dynamics and objectives, including rough-volatility settings \citep{gonon2021deephedging,horvath2021deephedging} and empirical implementations on market data \citep{mikkila2023empirical}. Reinforcement-learning and dynamic-programming viewpoints further emphasize sequential decision structure, rather than one-shot regression of hedge ratios \citep{buehler2022deepbellman,murray2022continuous}. 

However, robustness in this literature is typically assessed either (i) in-sample / held-out paths generated from the same simulator or statistical model, or (ii) via a small number of stress configurations. These evaluations do not deliver a comparable \emph{stress-severity indexed} robustness curve, and they do not isolate the failure mode studied here: policies exploiting regime-contingent microstructure correlations that invert when intermediation constraints bind. Our stress-operator evaluation explicitly targets this issue by comparing policies under worst-case KL tilts of the baseline path measure.

\subsection{Market Microstructure, Constraints, and Stress Episodes}

In asymmetric-information microstructure models, impact and spreads arise endogenously from adverse selection and liquidity provision \citep{kyle1985continuous,glosten1985bid}. Funding constraints can interact with market liquidity to generate nonlinear deterioration in execution conditions \citep{brunnermeier2009liquidity}. Empirical work documents persistent and state-dependent impact and liquidity dynamics \citep{bouchaud2008digest,gatheral2012impact}, and toxicity proxies such as VPIN are designed to capture adverse-selection conditions that vary over time \citep{easley2012vpin}. These mechanisms motivate our key distinction: microstructure variables are equilibrium outcomes, so their mapping to execution costs can be regime-dependent and can change sign.

This regime dependence is not only theoretical. The March 2020 episode provides a canonical illustration of constraint-driven liquidity deterioration in high-quality markets: dealer balance-sheet usage and intermediation capacity constraints were associated with sharp losses in Treasury market functionality \citep{he2022treasury,duffie2023dealer}. Related evidence from credit markets shows abrupt increases in trading costs and dislocations consistent with binding intermediation frictions \citep{haddad2021viral,kargar2021bondliquidity}. These episodes support the practical relevance of our mechanism: observable activity (including volume and order flow) can surge while execution costs worsen, making “high activity $\Rightarrow$ cheap trading” an unreliable rule across regimes.

\subsection{Relative-Entropy Uncertainty, Robust Control, and Model Risk}

Robust control evaluates decisions under model uncertainty by considering alternative probability models in a neighborhood of a reference model, with relative entropy (KL) providing a canonical notion of distance \citep{hansen2001robust,hansen2008robust}. The Donsker--Varadhan representation yields a tractable dual form and interprets worst-case evaluation as exponential tilting of the baseline model \citep{donskervaradhan1975}. In quantitative risk management, relative-entropy neighborhoods have been used to quantify model risk and derive computable worst-case bounds with minimal overhead beyond baseline Monte Carlo \citep{glasserman2014modelrisk}. 

We adopt this perspective at the level of \emph{path measures} around the training distribution used to learn a hedging policy. This produces a robustness curve indexed by a single stress budget, enabling apples-to-apples comparisons across hedges. The novelty in our setting is not KL robustness alone, but its combination with representation parsimony: we study how a controller’s information usage affects susceptibility to KL-bounded adversarial reweighting.

\subsection{Distribution Shift and Robustness in ML}

A broad ML literature emphasizes that out-of-distribution generalization depends on stability of relationships across environments rather than in-sample fit alone \citep{arjovsky2019invariant,sagawa2019distributionally}. Our setting differs in that stress affects both state visitation and action costs (execution), so we evaluate robustness through adversarial reweighting of baseline \emph{paths} rather than supervised prediction under labeled environments.


\subsection{Information Costs and Representation Parsimony}

Rational inattention formalizes decision-making under limited information-processing capacity \citep{sims2003rational}. The information bottleneck and its variational implementations provide an operational route to penalize representation complexity via KL-to-prior terms \citep{tishby2000information,alemi2017deep}. In sequential control, relative-entropy penalties can be interpreted as priced deviations from a reference dynamics or policy, supporting tractable control-as-inference formulations \citep{todorov2009linearly,rawlik2013stochastic}. 

We use an \emph{inner} KL-to-prior penalty as an explicit information budget on the learned representation. This inner information cost is conceptually distinct from the \emph{outer} KL defining the stress neighborhood: the outer KL governs model uncertainty over market paths, while the inner KL prices how much distribution-specific detail the policy encodes. Our empirical question is whether tightening the inner information budget mitigates vulnerability to regime-dependent microstructure semantics, thereby flattening the robustness curve under KL stress.


\section{Model and Theoretical Framework}
\label{sec:framework}

This section presents the hedging setup, regime-dependent execution costs, and the information-constrained architecture.
We then define semantic inversion and introduce a KL-bounded stress operator that produces a stress-severity indexed robustness curve. Finally, we provide a stylized mechanism linking the inner KL information cost to robustness under semantic inversion.

\subsection{Problem Setup}
\label{subsec:model_setup}

We consider discrete-time hedging at times $t=0,1,\dots,T$. Let $S_t$ denote the underlying price process. The hedger trades $d$ hedging instruments with (discounted) price vector $H_t\in\mathbb{R}^d$; the single-instrument case $d=1$ with $H_t=S_t$ is used in our experiments unless stated otherwise. The terminal liability is a random variable $L$ (e.g., a European payoff), measurable with respect to terminal market information.

Market conditions are indexed by a regime label $r\in\mathcal{R}$. For each $r$, let $P_r$ denote a probability measure over market trajectories and observed features:
\[
\big(H_{0:T},\,X_{0:T},\,L\big)\sim P_r,
\]
where $X_t$ is the time-$t$ observable feature vector available to the hedger (e.g., contract state and Greeks, microstructure proxies, or their concatenation). In our empirical protocol, the regime is \emph{episode-wise} (each path is drawn from $P_0$ or $P_1$); we defer within-path regime switching to the simulator specification in Section~\ref{sec:methodology}.

At each time $t$, the hedger chooses a post-trade position $a_t\in\mathbb{R}^d$. We allow the trading rule to act on a (possibly stochastic) representation $Z_t$ of the observation. A representation mechanism (encoder) produces $Z_t$ from the observation, and a policy maps $Z_t$ to positions:
\[
Z_t \sim p_\phi(\cdot \mid X_t), 
\qquad 
a_t = \pi_\theta(Z_t),
\]
where $\phi$ parameterizes the encoder and $\theta$ parameterizes the trading rule. Trades are $\Delta a_t := a_t-a_{t-1}$ with $a_{-1}:=0$.
In our implementation, $p_\phi(\cdot\mid X_t)$ is a Gaussian encoder (Section~\ref{subsec:info_constrained_policy}); no distributional assumption is imposed on the observed state $X_t$.

\subsection{Execution Costs and Semantic Inversion}
\label{subsec:cost_model}

Trading incurs regime- and state-dependent execution costs. Let
\[
C_{r,t}(\Delta a_t; X_t)
\]
denote the cost of trading $\Delta a_t$ at time $t$ in regime $r$, conditional on the observed microstructure state $X_t$ (capturing spreads, market impact, constraints, or other execution effects). This state dependence is essential: the core mechanism studied in this paper is that the mapping from microstructure proxies (e.g., volume) to marginal execution costs can change across regimes.

\begin{definition}[Semantic inversion]
\label{def:semantic_inversion}
Fix a feature coordinate $j$ of the observable state $x\in\mathcal{X}$. Consider a scalar execution-cost coefficient
$m_{r,t}(x)$ (e.g., an element of the spread term $s_{r,t}(x)$ or an element of the impact matrix $\Lambda_{r,t}(x)$
in \eqref{eq:cost_generic}; in the single-instrument quadratic case this can be the impact coefficient $\lambda_{r,t}(x)$).
We say that feature $x_j$ exhibits \emph{semantic inversion} between regimes $r=0$ and $r=1$ if there exist
$t$ and $x$ such that
\[
\frac{\partial m_{0,t}(x)}{\partial x_j}\cdot \frac{\partial m_{1,t}(x)}{\partial x_j} < 0.
\]
Equivalently, increasing $x_j$ moves marginal execution costs in opposite directions across regimes.
\end{definition}

In our experiments we take $m_{r,t}(x)=\lambda_{r,t}(x)$, so semantic inversion is diagnosed by a sign flip in
$\partial \lambda_{r,t}/\partial \mathrm{Vol}_t$ across regimes.

Definition~\ref{def:semantic_inversion} formalizes the regime-dependent meaning of microstructure proxies by focusing on the sign of their effect on \emph{marginal} execution costs. This captures the mechanism emphasized in asymmetric-information microstructure models, where impact depends on adverse selection and the informational content of order flow \citep{kyle1985continuous,glosten1985bid}. It also aligns with liquidity-spiral dynamics: when funding constraints tighten, intermediation capacity falls and impact rises endogenously \citep{brunnermeier2009liquidity}, so proxies that correlate with execution quality in normal times can weaken or invert in stress.

A convenient generic specification (used in our experiments) is a spread-plus-impact form,
\begin{equation}
\label{eq:cost_generic}
C_{r,t}(\Delta a_t;X_t)
=
s_{r,t}(X_t)\,\|\Delta a_t\|_1
+\frac{1}{2}\,\Delta a_t^\top \Lambda_{r,t}(X_t)\,\Delta a_t,
\end{equation}
where $s_{r,t}(X_t)\ge 0$ is an effective spread term and $\Lambda_{r,t}(X_t)\succeq 0$ is an impact matrix. Semantic inversion is represented by regime-dependent responses of $(s_{r,t},\Lambda_{r,t})$ to the same observed proxy: for example, the impact sensitivity to a volume feature can be decreasing in volume under $r=0$ (volume as depth) but increasing under $r=1$ (volume as toxic liquidation), as specified in Section~\ref{sec:methodology}.

\subsection{Hedging Error and Risk}
\label{subsec:hedge_error_risk}

Given $(\pi_\theta,p_\phi)$, the terminal hedging error under regime $r$ is
\begin{equation}
\label{eq:hedge_error}
Y^{\theta,\phi}_r
:=
L
-\sum_{t=0}^{T-1} a_t^\top(H_{t+1}-H_t)
-\sum_{t=0}^{T-1} C_{r,t}(\Delta a_t;X_t).
\end{equation}
We treat $Y^{\theta,\phi}_r$ as a loss variable (larger is worse), so tail-risk functionals such as ES are applied to $Y$. Thus $Y^{\theta,\phi}_r$ equals liability minus cumulative trading gains minus execution costs. Let $\rho(\cdot)$ be a tail-risk functional (e.g., Expected Shortfall $\mathrm{ES}_\gamma$). The regime-$r$ risk of a policy is
\begin{equation}
\label{eq:regime_risk}
R_r(\theta,\phi) := \rho\!\left(Y^{\theta,\phi}_r\right),
\end{equation}
where the distribution of $Y^{\theta,\phi}_r$ is induced by $P_r$ and the policy dynamics.
We summarize out-of-regime degradation by quantities such as
\[
\Delta R := R_1 - R_0,
\qquad
\mathrm{Deg} := \frac{R_1}{R_0},
\]
together with trading diagnostics (turnover and incurred costs).

\subsection{Information-Constrained Policy}
\label{subsec:info_constrained_policy}

Occam's Hedge constrains how much distribution-specific detail the controller extracts from observations by penalizing representation information. We adopt a stochastic encoder with a reference prior $p(z)$ (e.g., $\mathcal{N}(0,I)$). In our implementation,
\[
p_\phi(z_t\mid X_t) = \mathcal{N}\!\big(\mu_\phi(X_t),\mathrm{diag}(\sigma_\phi^2(X_t))\big),
\qquad
p(z)=\mathcal{N}(0,I).
\]
Define the per-step information cost as a KL-to-prior,
\[
\mathrm{IC}_t(\phi)
:=
\mathrm{KL}\!\left(p_\phi(Z_t\mid X_t)\,\|\,p(Z_t)\right),
\]
and the (time-averaged) representation information cost under the baseline measure $P_0$ as
\begin{equation}
\label{eq:info_cost}
\mathcal{C}(\phi)
:=
\mathbb{E}_{P_0}\!\left[\frac{1}{T}\sum_{t=0}^{T-1}\mathrm{IC}_t(\phi)\right].
\end{equation}
This inner KL term operationalizes a representation bandwidth constraint: larger $\mathcal{C}(\phi)$ indicates that the encoder departs more from a regime-agnostic codebook in order to encode fine-grained, potentially regime-contingent detail.

\subsection{KL Stress Operator and Robust Evaluation}
\label{subsec:kl_stress_operator}

Having defined baseline risk, we now introduce a stress operator for robustness evaluation. Fix the baseline (training) path measure $P_0$. Let $Y^{\theta,\phi}$ denote the terminal hedging error induced by the policy $(\pi_\theta,p_\phi)$ under baseline dynamics, viewed as a random variable on the baseline path space. Performance is measured with a tail-risk functional; we focus on Expected Shortfall $\mathrm{ES}_\gamma$ at confidence level $\gamma\in(0,1)$.

A standard convex representation of ES is
\begin{equation}
\label{eq:es_dual_q}
\mathrm{ES}_\gamma(Y)
=\min_{q\in\mathbb{R}}
\left\{
q+\frac{1}{1-\gamma}\,\mathbb{E}\big[(Y-q)_+\big]
\right\},
\end{equation}
which motivates the sample-wise convex loss
\begin{equation}
\label{eq:es_loss}
\ell_q(y)
:= q+\frac{1}{1-\gamma}(y-q)_+.
\end{equation}

\paragraph{Relative-entropy uncertainty set.}
For a stress budget $\eta\ge 0$, define the KL neighborhood
\begin{equation}
\label{eq:kl_ball}
\mathcal{U}_\eta(P_0)
:=
\left\{
Q\ll P_0:\;
\mathrm{KL}(Q\|P_0)\le \eta
\right\},
\qquad
\mathrm{KL}(Q\|P_0)
=
\mathbb{E}_Q\!\left[\log\frac{dQ}{dP_0}\right].
\end{equation}
We call this divergence the \emph{outer} KL when emphasizing distributional drift over path measures.

\paragraph{KL-stressed Expected Shortfall.}
To preserve ES semantics under stress, we place the ES dual inside the adversarial evaluation and define
\begin{equation}
\label{eq:kl_stressed_es}
R_\eta(\theta,\phi)
:=
\min_{q\in\mathbb{R}}
\sup_{Q\in\mathcal{U}_\eta(P_0)}
\mathbb{E}_Q\!\left[\ell_q\!\left(Y^{\theta,\phi}\right)\right].
\end{equation}
Here $Y^{\theta,\phi}$ denotes the baseline hedging error random variable evaluated under an alternative measure $Q$ on the same path space (i.e., a reweighting of baseline paths). The scalar $\eta$ indexes stress severity and produces a robustness curve $\eta\mapsto R_\eta(\theta,\phi)$.

\paragraph{Variational (Donsker--Varadhan) form.}
A direct application of the Donsker--Varadhan variational principle \citep{donskervaradhan1975} yields: for fixed $q$ and under mild integrability conditions,
\begin{equation}
\label{eq:dv_for_es_loss}
\sup_{Q\in\mathcal{U}_\eta(P_0)}
\mathbb{E}_Q\!\left[\ell_q\!\left(Y^{\theta,\phi}\right)\right]
=
\inf_{\lambda>0}
\frac{1}{\lambda}
\left(
\log \mathbb{E}_{P_0}\!\left[\exp\!\left(\lambda\,\ell_q\!\left(Y^{\theta,\phi}\right)\right)\right]
+\eta
\right).
\end{equation}
Thus $R_\eta$ can be estimated from baseline samples via a log-sum-exp estimator and one-dimensional optimization over the Lagrange multiplier $\lambda$, together with the outer minimization over $q$.

\paragraph{Why KL (relative entropy).}
We use relative entropy because it yields (i) a tractable dual representation for worst-case expectations (Donsker--Varadhan), (ii) a natural exponential tilting interpretation on \emph{path space}, and (iii) a clean composition with the inner KL information cost used to budget representation sensitivity. While Wasserstein-based uncertainty sets offer alternative notions of distributional robustness with geometric transport interpretations, we use relative entropy because it (i) yields a tractable Donsker--Varadhan dual form, (ii) naturally composes with our information-theoretic representation cost, and (iii) admits a clean exponential tilting interpretation on path space. 

\paragraph{Limitation.}
The uncertainty set $\mathcal{U}_\eta(P_0)$ only contains measures $Q$ that are absolutely continuous with respect to $P_0$.
Therefore, KL stress can \emph{reweight} baseline trajectories but cannot assign mass to states outside the support of $P_0$.
We interpret $\eta$ as a controlled local stress around the training distribution, complementary to discrete regime simulation
(which may introduce genuinely new states).


\paragraph{Estimation and numerical stability.}
In experiments, we estimate \eqref{eq:dv_for_es_loss} from baseline Monte Carlo samples $\{\omega_i\}_{i=1}^n\sim P_0$ using a stabilized log-sum-exp estimator:
\[
\log \widehat{\mathbb{E}}_{P_0}\!\left[\exp(\lambda \ell_q)\right]
=
m + \log\left(\frac{1}{n}\sum_{i=1}^n \exp\big(\lambda \ell_q(Y^{\theta,\phi}(\omega_i))-m\big)
\right),
\qquad
m := \max_i \lambda \ell_q(\omega_i).
\]
We optimize over $\lambda>0$ via one-dimensional convex search on a bounded interval, and we report robustness curves with uncertainty across random seeds to reflect estimator variance in the exponential tilting regime.

\begin{proposition}[Exponential tilting under KL stress]
\label{prop:kl_tilt}
Assume $\mathbb{E}_{P_0}[\exp(\lambda\,\ell_q(Y^{\theta,\phi}))]<\infty$ for some $\lambda>0$. For fixed $(q,\lambda)$, the maximizer in \eqref{eq:dv_for_es_loss} is attained by an exponential tilt of $P_0$:
\[
\frac{dQ^\star_{\lambda,q}}{dP_0}(\omega)
=
\frac{\exp\!\left(\lambda\,\ell_q\!\left(Y^{\theta,\phi}(\omega)\right)\right)}
{\mathbb{E}_{P_0}\!\left[\exp\!\left(\lambda\,\ell_q\!\left(Y^{\theta,\phi}\right)\right)\right]}.
\]
\end{proposition}

\paragraph{Proof sketch.}
Fix $q$ and introduce a Lagrangian for the constrained maximization of $\mathbb{E}_Q[\ell_q(Y^{\theta,\phi})]$ subject to $\mathrm{KL}(Q\|P_0)\le \eta$ and $\mathbb{E}_{P_0}\!\left[\frac{dQ}{dP_0}\right]=1$. Optimizing pointwise over the Radon--Nikodym derivative yields $\frac{dQ^\star}{dP_0}\propto \exp(\lambda\,\ell_q)$, and substituting back gives \eqref{eq:dv_for_es_loss}. A complete proof is standard; see \citet{donskervaradhan1975} and is reproduced in Appendix~\ref{app:dv_proof}.

\paragraph{Remark (Discrete regimes as specific tilts).}
If a stress regime $P_1$ satisfies $P_1\ll P_0$, then $P_1(d\omega)=w_1(\omega)\,P_0(d\omega)$ with $w_1=\frac{dP_1}{dP_0}$ and $\mathbb{E}_{P_0}[w_1]=1$. In this case, expected losses under $P_1$ can be written as weighted baseline losses:
\[
\mathbb{E}_{P_1}[\ell(Y)] = \mathbb{E}_{P_0}[w_1\,\ell(Y)].
\]
In our experiments we also report $\eta_1 := \mathrm{KL}(P_1\|P_0)$ (estimated from simulator densities) to relate the discrete stress scenario to the continuous robustness curve $\eta\mapsto R_\eta$.

\subsection{Dual-KL Mechanism and Robustness--Information Frontier}
\label{subsec:frontier}

We now connect the stress operator to representation parsimony by measuring how much distribution-specific detail the policy encodes and relating this information cost to robustness under KL-bounded reweighting. We separate the policy $\pi_\theta$ from the representation mechanism because representation choice is the core object of interest. While mutual information quantities such as $I(X;Z)$ or $I(Z;L)$ are conceptually relevant, they are not directly optimized in our implementation. Instead we use a tractable proxy standard in variational information bottleneck methods: a KL-to-prior penalty.

Let $Z_t$ be produced by a stochastic encoder $p_\phi(z_t\mid X_t)$ with reference prior $p(z)$ (e.g., $\mathcal{N}(0,I)$). We use the same notation as in Section~\ref{subsec:model_setup} and define the time-averaged information cost under the baseline measure:
\begin{equation}
\label{eq:info_cost_theory}
\mathcal{C}(\phi)
:=
\mathbb{E}_{P_0}\!\left[\frac{1}{T}\sum_{t=0}^{T-1}
\mathrm{KL}\!\left(p_\phi(Z_t\mid X_t)\,\|\,p(Z_t)\right)\right].
\end{equation}
In variational information bottleneck formulations, $\mathcal{C}(\phi)$ upper-bounds an information quantity between inputs and representations under suitable choices of $p(z)$ \citep{alemi2017deep,tishby2000information}, and it acts as a priced information flow constraint in sequential decision problems \citep{todorov2009linearly,rawlik2013stochastic}.

\paragraph{Dual-KL mechanism (hypothesis).}
The two divergences play distinct roles. The \emph{outer} KL defines the adversarial family of alternative market path measures used for stress evaluation, while the \emph{inner} KL in \eqref{eq:info_cost_theory} prices how much distribution-specific detail the encoder extracts from observations. Our central hypothesis is that tightening the inner information budget reduces reliance on regime-contingent microstructure mappings that satisfy Definition~\ref{def:semantic_inversion}, thereby making performance less sensitive to KL-bounded reweighting. Empirically, this should appear as a flatter robustness curve $\eta\mapsto R_\eta$ at matched baseline risk.

Training minimizes baseline risk plus an information penalty (Section~\ref{subsec:training_and_stress}):
\[
\min_{\theta,\phi}\; R_0(\theta,\phi)+\beta\,\mathcal{C}(\phi).
\]
Sweeping $\beta$ traces a frontier between baseline performance and representation information cost, and the same trained policies can be evaluated under KL stress. We report triplets
\[
\Big(R_0(\theta,\phi),\; R_\eta(\theta,\phi),\; \mathcal{C}(\phi)\Big)
\]
as $\beta$ varies (and as $\eta$ varies for robustness curves). Occam's Hedge predicts that, at comparable baseline performance $R_0$, policies with lower $\mathcal{C}(\phi)$ exhibit slower growth of $R_\eta$ with $\eta$; this prediction is assessed in Section~\ref{sec:experiments}.

\subsection{Mechanism: Information Penalties Suppress Semantically Unstable Features}
\label{subsec:mechanism}

This subsection provides a stylized mechanism linking the inner KL information cost to robustness under semantic inversion. The core point is not that the information bottleneck ``knows'' regimes; it is that regime-contingent microstructure correlations tend to be (i) high-variance across paths and (ii) valuable only in narrow regions of the baseline state distribution. Exploiting them typically requires the representation to encode fine-grained detail about $X_t$, which carries a direct KL cost. In contrast, payoff-anchored structural signals (Greeks) tend to reduce loss more uniformly across baseline paths and therefore survive under an information budget.

To make this precise, consider a one-step stylized model with two scalar features $x=(x^{\mathrm{st}},x^{\mathrm{inv}})$: a structurally stable coordinate $x^{\mathrm{st}}$ and a semantically inverting coordinate $x^{\mathrm{inv}}$. Let the encoder be Gaussian with mean linear in $x$ and fixed diagonal variance,
\[
Z = W x + \sigma \epsilon,\qquad \epsilon\sim\mathcal{N}(0,I),
\]
with prior $p(z)=\mathcal{N}(0,I)$. For this encoder family, the KL-to-prior satisfies
\[
\mathrm{KL}\big(p_\phi(Z\mid x)\,\|\,\mathcal{N}(0,I)\big)
= \tfrac12 \|W x\|^2 + \tfrac12\sum_k (\sigma_k^2-\log\sigma_k^2-1).
\]
Thus, making the representation sensitive to a feature direction (large $W$ along that coordinate) incurs an explicit information cost.

Now suppose the policy is linear in $Z$ and the baseline regime admits a correlation between $x^{\mathrm{inv}}$ and low execution costs, but stress reverses the marginal effect of $x^{\mathrm{inv}}$ on costs (semantic inversion as in Definition~\ref{def:semantic_inversion}). Under KL stress, the worst-case reweighting in Proposition~\ref{prop:kl_tilt} amplifies paths with large ES loss, which in this stylized setting correspond to regions where the $x^{\mathrm{inv}}$-based trading rule induces systematically poor execution outcomes under inversion. A representation that heavily encodes $x^{\mathrm{inv}}$ therefore creates larger tail losses available for the adversary to exploit, steepening the robustness curve $\eta\mapsto R_\eta$.

The inner information penalty mitigates this by making such high-sensitivity encodings expensive: for fixed baseline risk targets, increasing the information penalty $\beta$ shifts the optimal representation toward directions that reduce loss broadly without requiring high feature sensitivity. This predicts that (i) microstructure-heavy policies have larger $\mathcal{C}(\phi)$ and steeper $R_\eta$ growth, and (ii) increasing $\beta$ reduces both $\mathcal{C}(\phi)$ and the slope of $R_\eta$ at matched baseline risk, producing a robustness--information frontier.



\section{Methodology}
\label{sec:methodology}

This section describes the controlled regime-switching simulator, the representation sets (Greeks versus microstructure proxies), the Occam-regularized architecture (encoder + policy), and evaluation metrics.

\subsection{Controlled Regime-Switching Simulator}
We construct two environments. The normal regime (Regime 0) represents moderate volatility and stable intermediation. The stress regime (Regime 1) represents high volatility with deteriorating market liquidity driven by binding funding constraints. The simulator is designed so that an observed microstructure proxy can \emph{invert economic meaning} across regimes: in Regime 0, elevated market activity predominantly coincides with depth and risk-sharing capacity; in Regime 1, elevated market activity predominantly coincides with toxic flow and forced liquidation.

This inversion is grounded in two standard microstructure mechanisms. First, in adverse-selection models, price impact reflects the informational content of order flow; when the composition of flow shifts toward informed or toxic trading, the same observed activity can correspond to higher expected adverse selection and hence higher impact. Second, in liquidity spiral models, funding constraints tighten endogenously under stress, reducing intermediation capacity and amplifying price impact precisely when liquidation pressure is high. Together, these mechanisms imply that the mapping from observed order-flow proxies to execution quality is not invariant across regimes and can flip sign when constraints bind. Together, these mechanisms exemplify a broader point: microstructure proxies are equilibrium outcomes, so their mapping to marginal execution costs is inherently regime-dependent and can change sign when either information composition or intermediation constraints shift.


We introduce a latent toxicity state $\alpha_t$ affecting both observed microstructure proxies and execution costs. We also include a funding-liquidity state $m_t$ (interpretable as margin tightness) whose dynamics incorporate feedback from market moves and hedging losses, consistent with \citep{brunnermeier2009liquidity}. This yields an endogenous channel through which liquidity provision deteriorates and microstructure semantics can invert.

\paragraph{Observed microstructure proxies and latent states.}
We work with a \emph{dimensionless} market-activity proxy $\mathrm{Vol}_t$ constructed from raw traded volume $\mathrm{Vol}^{\mathrm{raw}}_t$ by normalizing against a slow-moving baseline $\overline{\mathrm{Vol}}_t$ (e.g., an exponential moving average):
\[
\tilde v_t := \log\!\left(\frac{\mathrm{Vol}^{\mathrm{raw}}_t}{\overline{\mathrm{Vol}}_t}\right), 
\qquad 
\mathrm{Vol}_t := \exp(\mathrm{clip}(\tilde v_t,\, v_{\min},\, v_{\max}))\;\;\ge \epsilon.
\]
The clipping bounds and the floor $\epsilon>0$ ensure numerical stability and prevent $\mathrm{Vol}_t^{-1}$ from exploding. The stress regime is characterized not only by higher volatility but also by a stronger loading of observed activity on toxicity:
\[
\tilde v_t = \mu_{v,r} + b_{v,r}\alpha_t + \sigma_{v,r}\varepsilon^v_t,
\qquad b_{v,1} > b_{v,0},
\]
so that in Regime 1, elevated observed activity is more likely to reflect toxic flow. We also model the effective spread proxy as widening with toxicity and margin tightness,
\[
\mathrm{spr}_{r,t} = \mathrm{spr}_r \exp(\gamma_{\alpha}\alpha_t)\exp(\gamma_m m_t),
\]
which makes the statement ``$\alpha_t$ affects observed proxies'' literally true.

For completeness, the latent states follow stable mean-reverting dynamics with regime-dependent baselines. Toxicity evolves as
\[
\alpha_{t+1} = \rho_\alpha \alpha_t + (1-\rho_\alpha)\bar\alpha_r + \sigma_{\alpha,r}\varepsilon^\alpha_t,
\qquad |\rho_\alpha|<1,
\]
while margin tightness evolves with feedback from market moves and realized hedging strain,
\[
m_{t+1} = \rho_m m_t + (1-\rho_m)\bar m_r + \gamma_S|\Delta S_t| + \gamma_Y|Y_t| + \sigma_{m,r}\varepsilon^m_t,
\qquad |\rho_m|<1,
\]
where $\Delta S_t:=S_t-S_{t-1}$ and $Y_t$ denotes the running hedging P\&L (or tracking error) increment. This introduces an endogenous liquidity spiral channel: large market moves and hedging losses increase $m_t$, which worsens execution conditions and can amplify subsequent losses.

\paragraph{Execution costs and semantic inversion.}
Transaction costs include a spread component and a convex impact component. The hedge position $a_t$ is measured in \emph{units of the underlying} (e.g., shares), so a trade is $\Delta a_t:=a_t-a_{t-1}$. For a trade in regime $r$, we use
\[
C_{r,t}(\Delta a_t)=c_{\mathrm{spr}}\mathrm{spr}_{r,t}\lvert \Delta a_t\rvert+\frac{1}{2}\lambda_{r,t}(\Delta a_t)^2,
\]
where $\lambda_{r,t}$ is an effective impact coefficient and $\mathrm{spr}_{r,t}$ is the effective spread proxy defined above.

To encode the regime-dependence of the \emph{economic meaning} of observed activity, we let the normalized activity proxy enter the impact coefficient with opposite sign across regimes:
\[
\lambda_{r,t}=\lambda_r\, g_r(\mathrm{Vol}_t)\exp(\kappa_\alpha \alpha_t)\exp(\kappa_m m_t),
\]
where $\alpha_t$ represents adverse selection (toxicity) and $m_t$ represents funding tightness (margin pressure). We choose
\[
\begin{aligned}
g_0(\mathrm{Vol}) &= \mathrm{Vol}^{-1}
&& \text{(Regime 0: high activity $\Rightarrow$ depth $\Rightarrow$ lower impact)},\\
g_1(\mathrm{Vol}) &= \mathrm{Vol}
&& \text{(Regime 1: high activity $\Rightarrow$ toxic liquidation $\Rightarrow$ higher impact)}.
\end{aligned}
\]

This is a stylized reduced-form representation of the microstructure fact that order-flow proxies are equilibrium objects: the same signal can map to different execution conditions when the composition of trading and intermediation constraints change. Under this mechanism, a policy trained in Regime 0 that internalizes ``high volume means cheap trading'' will overtrade into Regime 1, amplifying execution costs precisely when funding constraints bind and adverse selection rises (consistent with classic adverse selection impact intuition).

\paragraph{Liability and Greeks.}
We hedge a European option liability $L$ (call or put). Greeks are computed using a pricing map that can be imperfect (e.g., using instantaneous variance as an implied volatility proxy), reflecting realistic model error while preserving payoff anchoring.

\subsection{Representations}

At each time $t$, the policy observes one of the following representations:
\begin{itemize}
\item \textbf{Greeks-only:} payoff-anchored sensitivities (e.g., delta, gamma, vega) and contract state (e.g., moneyness, time-to-maturity).
\item \textbf{Microstructure-only:} proxies such as volume, order imbalance, short-horizon return/momentum, and spread/impact indicators.
\item \textbf{Combined:} the union of Greeks and microstructure proxies.
\end{itemize}
All policies share the same action space and risk objective; only the observed representation changes.

\subsection{Occam-Regularized Architecture}

We implement a variational encoder. Given input $x_t$, the encoder outputs $(\mu_\phi(x_t),\sigma_\phi(x_t))$ and defines
\[
z_t=\mu_\phi(x_t)+\sigma_\phi(x_t)\odot \epsilon_t,\qquad \epsilon_t\sim\mathcal{N}(0,I).
\]
The policy maps $z_t$ to an action, either the target position $a_t$ or trade $\Delta a_t$. The information cost is the time-and-path average of $\mathrm{KL}(\mathcal{N}(\mu_\phi,\sigma_\phi^2)\,\|\,\mathcal{N}(0,I))$.

\subsection{Training and Evaluation}
\label{subsec:training_and_stress}

We train on Regime 0 only. The training objective is
\begin{equation}
\label{eq:hedge_objective}
\min_{\theta,\phi}\;\widehat{R}_0(\theta,\phi)+\beta\,\widehat{\mathcal{C}}(\phi).
\end{equation}
where $\widehat{R}_0$ is an empirical estimate of a tail-risk measure of terminal hedging error $Y$ (e.g., Expected Shortfall at a fixed level) and $\widehat{\mathcal{C}}(\phi)$ is the empirical information cost.


We evaluate each trained policy on Regime 0 and Regime 1, reporting:
\begin{itemize}
\item Tail risk of hedging error (e.g., ES and/or VaR of $Y$),
\item Mean and variance of $Y$,
\item Average trading cost and turnover (e.g., $\sum_t \|a_t-a_{t-1}\|$),
\item \textbf{Degradation:} difference or ratio of stress risk to normal risk,
\item \textbf{Semantic instability diagnostics:} sign flips in $\partial \lambda_{r,t}/\partial \mathrm{Vol}_t$, changes in the association between volume and realized costs, and instability of simple predictive probes across regimes.
\end{itemize}

To separate Occam’s Hedge from generic regularization, we include:
(i) ERM deep hedging (no information penalty),
(ii) ERM with parameter regularization (weight decay / early stopping),
(iii) input-noise baselines (feature dropout and Gaussian noise on microstructure inputs),
(iv) a robust-training baseline that performs adversarial reweighting of baseline paths during training using the exponential-tilt weights implied by \eqref{eq:dv_for_es_loss} at a fixed stress budget.

\section{Experiments}
\label{sec:experiments}

We train solely on Regime 0 paths and evaluate on held-out Regime 0 and Regime 1 paths. We sweep $\beta$ to trace the tradeoff frontier between baseline risk and information cost, and we evaluate the corresponding stress risk along this frontier.

The main empirical questions are:
\begin{enumerate}
\item \textbf{Representation fragility.} Do microstructure-only policies exhibit larger stress degradation than Greeks-only policies, consistent with semantic instability under regime shifts?
\item \textbf{Occam effect.} For microstructure-heavy inputs, does increasing $\beta$ reduce turnover and mitigate stress degradation, consistent with reduced reliance on distribution-specific equilibrium detail?
\item \textbf{Combined representations.} Do combined inputs improve baseline risk but degrade in stress unless information cost is controlled, and does Occam regularization shift reliance toward more stable structural information?
\end{enumerate}

We summarize results using a small set of figures and tables: (i) baseline versus stress risk by representation class, (ii) the tradeoff frontier traced by $\beta$ with stress evaluation overlaid, and (iii) mechanism diagnostics demonstrating semantic inversion and differences in policy behavior.

All reported curves are averaged over multiple random seeds with confidence intervals. We also perform sensitivity analysis over the inversion-strength parameters governing $g_r(\mathrm{Vol})$ and the regime-dependent loading $b_{v,r}$ to verify that the robustness--information effects are not tied to a single calibration.


\section{Conclusion}

Deep hedging policies trained by ERM can exploit regime-contingent microstructure correlations that invert under stress, producing tail-risk blowups precisely when hedging is most needed. We introduced Occam’s Hedge under representation risk: representation-level principle governing the tradeoff between baseline risk, information cost, and robustness under execution-sensitive stress. The economic mechanism is semantic stability. Payoff-anchored structural representations (Greeks) are comparatively stable across regimes, while equilibrium-based microstructure signals are prone to concept drift, especially when funding constraints tighten and liquidity provision equilibria shift \citep{brunnermeier2009liquidity}.

Empirically, in a controlled regime-switching environment designed to induce semantic inversion in microstructure signals, we evaluate whether microstructure-heavy hedgers suffer larger out-of-regime degradation and whether information-cost regularization implemented via a variational encoder mitigates this degradation by limiting reliance on distribution-specific details. This provides a practical approach to model-risk-aware hedging: when expanding the information set, one should evaluate not only in-sample fit but also the information cost required to internalize the representation, since high information cost can signal fragile dependence on equilibrium conditions.

\section{Appendix}

\subsection{Proof of the Donsker--Varadhan form}
\label{app:dv_proof}
We sketch the standard variational argument. For any $Q\ll P_0$ with density $w=\frac{dQ}{dP_0}$,
\[
\mathbb{E}_Q[\ell_q(Y)]=\mathbb{E}_{P_0}[w\,\ell_q(Y)]
,\qquad \mathrm{KL}(Q\|P_0)=\mathbb{E}_{P_0}[w\log w].
\]
Introduce a Lagrangian with multiplier $\lambda>0$ for the KL constraint and optimize pointwise over $w$ under $\mathbb{E}_{P_0}[w]=1$. The optimizer satisfies
\[
w^\star(\omega)\propto \exp(\lambda \ell(\omega)),
\]
and substituting back yields \eqref{eq:dv_for_es_loss}.

\section*{Acknowledgments}
The author thanks colleagues and mentors for helpful discussions and feedback. Any remaining errors are the author’s own.

\section{References}
\begin{thebibliography}{99}

\bibitem[Brady(1988)]{brady1988report}
Nicholas~F. Brady.
\newblock Report of the Presidential Task Force on Market Mechanisms.
\newblock \emph{US Government Printing Office, Washington, DC}, 1988.

\bibitem[Bouchaud et al.(2008)]{bouchaud2008digest}
Jean-Philippe Bouchaud, J.~D. Farmer, and Fabrizio Lillo.
\newblock How markets slowly digest changes in supply and demand.
\newblock In \emph{Handbook of Financial Markets: Dynamics and Evolution}, 2008.

\bibitem[Brunnermeier and Pedersen(2009)]{brunnermeier2009liquidity}
Markus~K. Brunnermeier and Lasse~Heje Pedersen.
\newblock Market liquidity and funding liquidity.
\newblock \emph{The Review of Financial Studies}, 22(6):2201--2238, 2009.

\bibitem[B\"uhler et al.(2019)]{buehler2019deep}
Hans B\"uhler, Lukas Gonon, Josef Teichmann, and Ben Wood.
\newblock Deep hedging.
\newblock \emph{Quantitative Finance}, 19(8):1271--1291, 2019.

\bibitem[Coval et al.(2009)]{coval2009economic}
Joshua~D. Coval, Jakub~W. Jurek, and Erik Stafford.
\newblock The economics of structured finance.
\newblock \emph{Journal of Economic Perspectives}, 23(1):3--25, 2009.

\bibitem[Donsker and Varadhan(1975)]{donskervaradhan1975}
Monroe~D. Donsker and S.~R.~S. Varadhan.
\newblock Asymptotic evaluation of certain {M}arkov process expectations for large time.
\newblock \emph{Communications on Pure and Applied Mathematics}, 28(1):1--47, 1975.

\bibitem[Duffie(2020)]{duffie2020intermediation}
Darrell Duffie.
\newblock Intermediation of {U}.{S}. Treasury markets after the Covid-19 crisis.
\newblock \emph{Journal of Economic Perspectives}, 34(4):205--228, 2020.

\bibitem[Duffie(2023)]{duffie2023dealercapacity}
Darrell Duffie.
\newblock Intermediation capacity constraints and the structure of dealer markets.
\newblock \emph{Journal of Finance}, 78(6):3159--3211, 2023.

\bibitem[Easley et al.(2012)]{easley2012vpin}
David Easley, Marcos~M. L\'opez~de Prado, and Maureen O'Hara.
\newblock Flow toxicity and liquidity in a high-frequency world.
\newblock \emph{The Review of Financial Studies}, 25(5):1457--1493, 2012.

\bibitem[Glosten and Milgrom(1985)]{glosten1985bid}
Lawrence~R. Glosten and Paul~R. Milgrom.
\newblock Bid, ask and transaction prices in a specialist market with heterogeneously informed traders.
\newblock \emph{Journal of Financial Economics}, 14(1):71--100, 1985.

\bibitem[Hansen and Sargent(2001)]{hansen2001robust}
Lars Peter Hansen and Thomas~J. Sargent.
\newblock Robust control and model uncertainty.
\newblock \emph{American Economic Review}, 91(2):60--66, 2001.

\bibitem[Hansen and Sargent(2008)]{hansen2008robust}
Lars Peter Hansen and Thomas~J. Sargent.
\newblock \emph{Robustness}.
\newblock Princeton University Press, 2008.

\bibitem[Krueger et al.(2021)]{krueger2021out}
David Krueger, Ethan Caballero, Joern-Henrik Jacobsen, Amy Zhang, Jonathan Binas,
Dinghuai Zhang, Remi Le~Priol, and Aaron Courville.
\newblock Out-of-distribution generalization via risk extrapolation ({REx}).
\newblock \emph{International Conference on Learning Representations (ICLR)}, 2021.

\bibitem[Kyle(1985)]{kyle1985continuous}
Albert~S. Kyle.
\newblock Continuous auctions and insider trading.
\newblock \emph{Econometrica}, 53(6):1315--1335, 1985.

\bibitem[Lucas(1976)]{Lucas1976}
Robert~E. Lucas, Jr.
\newblock Econometric policy evaluation: A critique.
\newblock \emph{Carnegie-Rochester Conference Series on Public Policy}, 1:19--46, 1976.

\bibitem[Peters et al.(2016)]{peters2016causal}
Jonas Peters, Peter B{\"u}hlmann, and Nicolai Meinshausen.
\newblock Causal inference by using invariant prediction: Identification and confidence intervals.
\newblock \emph{Journal of the Royal Statistical Society: Series B}, 78(5):947--1012, 2016.

\bibitem[Rosenfeld et al.(2021)]{rosenfeld2021risks}
Elan Rosenfeld, Pradeep Ravikumar, and Andrej Risteski.
\newblock The risks of invariant risk minimization.
\newblock \emph{International Conference on Learning Representations (ICLR)}, 2021.

\bibitem[Ruf and Wang(2020)]{ruf2020hedging}
Johannes Ruf and Weiren Wang.
\newblock Hedging with neural networks.
\newblock \emph{SSRN Electronic Journal}, 3580132, 2020.

\bibitem[Sagawa et al.(2020)]{sagawa2019distributionally}
Shiori Sagawa, Pang~Wei Koh, Tatsunori~B. Hashimoto, and Percy Liang.
\newblock Distributionally robust neural networks for group shifts: On the importance of regularization for worst-case generalization.
\newblock \emph{International Conference on Learning Representations (ICLR)}, 2020.

\bibitem[Schrimpf et al.(2021)]{schrimpf2021leverage}
Andreas Schrimpf, Hyun~Song Shin, and Vladyslav Sushko.
\newblock Leverage and margin spirals in fixed income markets during the Covid-19 crisis.
\newblock \emph{BIS Bulletin}, No. 2, 2021.

\bibitem[Sims(2003)]{sims2003rational}
Christopher~A. Sims.
\newblock Rational inattention: A research agenda.
\newblock \emph{Deutsche Bundesbank Discussion Paper}, No. 34, 2003.

\bibitem[Tishby et al.(2000)]{tishby2000information}
Naftali Tishby, Fernando~C. Pereira, and William Bialek.
\newblock The information bottleneck method.
\newblock \emph{arXiv preprint physics/0004057}, 2000.

\bibitem[Vissing-J{\o}rgensen(2021)]{vissingjorgensen2021treasury}
Annette Vissing-J{\o}rgensen.
\newblock The Treasury market in spring 2020 and the response of the Federal Reserve.
\newblock \emph{Journal of Monetary Economics}, 120:19--47, 2021.

\bibitem[Ahuja et al.(2021)]{ahuja2021invariance}
Kartik Ahuja, Karthikeyan Shanmugam, Kush Varshney, and Amit Dhurandhar.
\newblock Invariant risk minimization games.
\newblock \emph{International Conference on Learning Representations (ICLR)}, 2021.

\bibitem[Alemi et al.(2017)]{alemi2017deep}
Alexander~A. Alemi, Ian Fischer, Joshua~V. Dillon, and Kevin Murphy.
\newblock Deep variational information bottleneck.
\newblock \emph{International Conference on Learning Representations (ICLR)}, 2017.

\bibitem[Amihud(2002)]{amihud2002illiquidity}
Yakov Amihud.
\newblock Illiquidity and stock returns: Cross-section and time-series effects.
\newblock \emph{Journal of Financial Markets}, 5(1):31--56, 2002.

\bibitem[Arjovsky et al.(2019)]{arjovsky2019invariant}
Martin Arjovsky, L\'eon Bottou, Ishaan Gulrajani, and David Lopez-Paz.
\newblock Invariant risk minimization.
\newblock \emph{arXiv preprint arXiv:1907.02893}, 2019.

\bibitem[Almgren and Chriss(2001)]{almgren2001optimal}
Robert Almgren and Neil Chriss.
\newblock Optimal execution of portfolio transactions.
\newblock \emph{Journal of Risk}, 3(2):5--39, 2001.

\bibitem[Artzner et al.(1999)]{artzner1999coherent}
Philippe Artzner, Freddy Delbaen, Jean-Marc Eber, and David Heath.
\newblock Coherent measures of risk.
\newblock \emph{Mathematical Finance}, 9(3):203--228, 1999.

\bibitem[F{\"o}llmer and Schied(2002)]{foellmer2002convex}
Hans F{\"o}llmer and Alexander Schied.
\newblock Convex measures of risk and trading constraints.
\newblock \emph{Finance and Stochastics}, 6(4):429--447, 2002.

\bibitem[Gonon et al.(2021)]{gonon2021deephedging}
Lukas Gonon, Josef Teichmann, and Ben Wood.
\newblock Deep hedging with rough volatility.
\newblock \emph{SIAM Journal on Financial Mathematics}, 12(2):631--663, 2021.

\bibitem[Horvath et al.(2021)]{horvath2021deephedging}
Blanka Horvath, Josef Teichmann, and Ben Wood.
\newblock Deep hedging under rough volatility.
\newblock \emph{Quantitative Finance}, 21(8):1351--1376, 2021.

\bibitem[Anderson et al.(2012)]{anderson2012robust}
Evan Anderson, Lars Peter Hansen, and Thomas~J. Sargent.
\newblock Robustness, detection, and the price of risk.
\newblock \emph{Journal of Economic Theory}, 147(1):369--399, 2012.

\bibitem[Todorov(2009)]{todorov2009linearly}
Emanuel Todorov.
\newblock Efficient computation of optimal actions.
\newblock \emph{Proceedings of the National Academy of Sciences}, 106(28):11478--11483, 2009.

\bibitem[Rawlik et al.(2013)]{rawlik2013stochastic}
Konrad Rawlik, Marc Toussaint, and Sethu Vijayakumar.
\newblock Stochastic optimal control as approximate inference.
\newblock In \emph{Robotics: Science and Systems}, 2013.

\bibitem[Hamilton(1989)]{hamilton1989markov}
James~D. Hamilton.
\newblock A new approach to the economic analysis of nonstationary time series and the business cycle.
\newblock \emph{Econometrica}, 57(2):357--384, 1989.

\bibitem[Gatheral et al.(2012)]{gatheral2012impact}
Jim Gatheral, Thibault Jaisson, and Mathieu Rosenbaum.
\newblock The volatility of high-frequency price changes.
\newblock \emph{Quantitative Finance}, 12(1):47--63, 2012.

\bibitem[B{\"u}hler et al.(2022)]{buehler2022deepbellman}
Hans B{\"u}hler, Philipp Murray, and Ben Wood.
\newblock Deep {B}ellman hedging.
\newblock \emph{arXiv preprint arXiv:2207.00932}, 2022.

\bibitem[Mikkil{\"a} and Kanniainen(2023)]{mikkila2023empirical}
Oskari Mikkil{\"a} and Juho Kanniainen.
\newblock Empirical deep hedging.
\newblock \emph{Quantitative Finance}, 23(1):111--122, 2023.

\bibitem[Murray et al.(2022)]{murray2022continuous}
Phillip Murray, Ben Wood, Hans B{\"u}hler, Magnus Wiese, and Mikko S. Pakkanen.
\newblock Deep hedging: Continuous reinforcement learning for hedging of general portfolios across multiple risk aversions.
\newblock \emph{arXiv preprint arXiv:2207.07467}, 2022.

\bibitem[He et al.(2022)]{he2022treasury}
Zhiguo He, Stefan Nagel, and Zhaogang Song.
\newblock Treasury inconvenience yields during the {COVID}-19 crisis.
\newblock \emph{Journal of Financial Economics}, 143(1):57--79, 2022.

\bibitem[Duffie et al.(2023)]{duffie2023dealer}
Darrell Duffie, Michael J. Fleming, Frank M. Keane, Claire Nelson, Or Shachar, and Peter Van Tassel.
\newblock Dealer capacity and {U}.{S}. {T}reasury market functionality.
\newblock \emph{Federal Reserve Bank of New York Staff Reports}, No.~1070, 2023.

\bibitem[Haddad et al.(2021)]{haddad2021viral}
Valentin Haddad, Alan Moreira, and Tyler Muir.
\newblock When selling becomes viral: Disruptions in debt markets in the {COVID}-19 crisis and the {F}ed's response.
\newblock \emph{The Review of Financial Studies}, 34(11):5309--5351, 2021.

\bibitem[Kargar et al.(2021)]{kargar2021bondliquidity}
Mahyar Kargar, Benjamin Lester, David Lindsay, Shuo Liu, Pierre-Olivier Weill, and Diego Z{\'u}{\~n}iga.
\newblock Corporate bond liquidity during the {COVID}-19 crisis.
\newblock \emph{The Review of Financial Studies}, 34(11):5352--5401, 2021.

\bibitem[Glasserman and Xu(2014)]{glasserman2014modelrisk}
Paul Glasserman and Xingbo Xu.
\newblock Robust risk measurement and model risk.
\newblock \emph{Quantitative Finance}, 14(1):29--58, 2014.

\end{thebibliography}

\end{document}